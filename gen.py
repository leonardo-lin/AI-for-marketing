import openai

import logging
from datetime import datetime
import search
import data_Compilation
import json
import os
from dotenv import load_dotenv
import data_Compilation
# 1. è¼‰å…¥ .env æª”
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# 2. è¨­å®š log æª”æ¡ˆï¼ˆä¾ç…§æ—¥æœŸå‘½åï¼‰
log_filename = "log\\"+datetime.now().strftime("%Y-%m-%d") + ".log"
logging.basicConfig(
    filename=log_filename,
    level=logging.INFO,
    format="%(asctime)s - %(message)s",
    encoding="utf-8"
)
conversation_history = [
    {"role": "system", "content": "You are a helpful assistant."}
]
def chat_with_gpt(prompt: str, model: str = "gpt-4o-mini"):
    
    try:
        # åŠ å…¥ä½¿ç”¨è€…è¼¸å…¥åˆ°æ­·å²
        

        response = openai.ChatCompletion.create(
            model=model,
            messages=conversation_history,
            temperature=0.7
        )

        reply = response["choices"][0]["message"]["content"].strip()

        # åŠ å…¥æ¨¡å‹å›è¦†åˆ°æ­·å²
        conversation_history.append({"role": "assistant", "content": reply})

        # ç´€éŒ„å°è©±åˆ° log
        logging.info(f"[USER] {prompt}")
        logging.info(f"[GPT]  {reply}")
        return reply
    except Exception as e:
        error_message = f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}"
        logging.error(error_message)
        return error_message
    

def mission_search_query(mission, model="gpt-4o-mini"):
    try:
        # åŠ å…¥æŒ‡ç¤ºç³»çµ±æç¤º
        prompt_messages = conversation_history + [
            {"role": "system", "content": "ä½ çš„ä»»å‹™æ˜¯{mission}ï¼Œå…ˆæ ¹æ“šä¸Šé¢èˆ‡ä½¿ç”¨è€…çš„å…§å®¹ï¼Œè«‹åˆ¤æ–·è¼¸å…¥å“ªäº›queryå¯ä»¥æœå°‹åˆ°èƒ½å¹«åŠ©å®Œæˆä»»å‹™çš„è³‡è¨Šï¼Œä¸¦ç”¢ç”Ÿæ•¸å€‹å…·é«”çš„æœå°‹æŸ¥è©¢èªå¥[\"Query1\",\"Query2\"...]ï¼Œä¸è¦è§£é‡‹ï¼Œåªè¼¸å‡º Query æœ¬èº«ï¼Œç”¨ä¸­æ‹¬å¼§åŒ…åœæˆlistæ ¼å¼ã€‚"}
        ]

        response = openai.ChatCompletion.create(
            model=model,
            messages=prompt_messages,
            temperature=0.5,
            max_tokens=100
        )
        query = response["choices"][0]["message"]["content"].strip()

        return query
    except Exception as e:
        return f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}"

def summarize_report(system_prompt, model = "gpt-4o-mini"):
    
    try:
        # åŠ å…¥æŒ‡ç¤ºç³»çµ±æç¤º
        prompt_messages = conversation_history + [
            {"role": "system", "content": system_prompt}
        ]

        response = openai.ChatCompletion.create(
            model=model,
            messages=prompt_messages,
            temperature=0.5,
            max_tokens=100
        )
        query = response["choices"][0]["message"]["content"].strip()
        
        return query
    except Exception as e:
        return f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}"

if __name__ == "__main__":
    print("ç¬¬ä¸€éšæ®µ: ç”¢å“åˆ†æ")
    product = ''
    # user_input = input("\nè«‹è¼¸å…¥ä½ çš„å•é¡Œï¼š")
    with open("product.txt",'r',encoding='utf-8')as f:
        product = f.read()
    # user_input = input("è«‹æè¿°ä½ çš„ç”¢å“ï¼Œè¶Šè©³ç´°è¶Šå¥½ï¼Œæˆ‘ä¾†å¹«ä½ åˆ†æä½ åœ¨å¸‚å ´ä¸Šçš„å®šä½ï¼š")
    print('ç”¢å“å…§å®¹'+product)
    # user_input = product
    conversation_history.append({"role": "user", "content": f'ä»¥ä¸‹ç‚ºæˆ‘çš„ç”¢å“æè¿°\n{product}'})
    system_prompt = 'è«‹é‡å°æˆ‘çš„ç”¢å“å¹«æˆ‘å¾å„é …ç¶²è·¯è³‡æºä¸Šæ‰¾åˆ°æˆ‘çš„å„ªå‹¢ç”¢å“å®šä½'
    anay = data_Compilation.mission_based_search_and_report(system_prompt+'\n'+product)
    print(anay)
    conversation_history.append({"role": "assistant", "content": f'ä»¥ä¸‹ç‚ºæˆ‘çš„ç”¢å“æè¿°\n{product}'})
    # reply = chat_with_gpt(user_input)
    # print("\nğŸ¤– GPT-4o-mini å›è¦†ï¼š\n" + reply)
    #éœ€è¦ä¸€å€‹RAGæ‰¾è³‡æ–™èˆ‡è³‡æ–™åˆ†æ
    # print(generate_search_query())
    
    
    
    while True:
        #RAG åˆ†æä¸Šä¸€å‰‡å°è©±
        user_input = input("ä½ å¯ä»¥åœ¨é€™é‚Šè£œå……ä½ çš„å¸‚å ´åœ°ä½ï¼Œæˆ–æ˜¯è¼¸å…¥exité€²å…¥å®¢æˆ¶å°‹æ‰¾éšæ®µï¼š")
        conversation_history.append({"role": "user", "content": user_input})
        # print(mission_search_query())
        if user_input.lower() in ["exit", "quit", "bye"]:
            print("ğŸ‘‹ é€²å…¥ä¸‹ä¸€éšæ®µï¼")
            break
        reply = chat_with_gpt(user_input)
        print("\nğŸ¤– GPT-4o-mini å›è¦†ï¼š\n" + reply)
    summary_report = summarize_report("è«‹é‡å°é€™æ®µå°è©±åšä¸€ä»½é‡å°æ–¼å•†å“çš„è©³æƒ…èˆ‡å¸‚å ´å®šä½åšä¸€ä»½è©³ç´°çš„ç¸½çµå ±å‘Š")
    # conversation_history = [{"role": "system", "content": f"ä»¥ä¸‹æ˜¯ä¸€ä»½æˆ‘å€‘å‰›å‰›è¨è«–é—œæ–¼ç”¢å“çš„å¸‚å ´å®šä½å ±å‘Š\n{summary_report}\n\nç¾åœ¨ä½ æ˜¯ä¸€ä½æ½›åœ¨å®¢æˆ¶é–‹ç™¼å°ˆå®¶ï¼Œä½ è¦è² è²¬å¹«æˆ‘åˆ†æå“ªé‚Šå¯ä»¥å¹«æˆ‘æ‰¾åˆ°æ½›åœ¨å®¢æˆ¶"}]
    conversation_history.append({"role": "system", "content": f"ç¾åœ¨ä½ æ˜¯ä¸€ä½æ½›åœ¨å®¢æˆ¶é–‹ç™¼å°ˆå®¶ï¼Œä½ è¦è² è²¬å¹«æˆ‘åˆ†æå“ªé‚Šå¯ä»¥å¹«æˆ‘æ‰¾åˆ°æ½›åœ¨å®¢æˆ¶"})
    

    
    
    print("ç”¢å“åˆ†æçµæŸï¼Œç¾åœ¨é€²å…¥æ½›åœ¨å®¢æˆ¶å°‹æ‰¾éšæ®µ")
    #å…ˆåšç¬¬ä¸€å€‹RAGæ‰¾è³‡æ–™
    report = data_Compilation.mission_based_search_and_report(mission = f'æ ¹æ“šä½¿ç”¨è€…å°æ–¼ç”¢å“çš„æè¿°{summary_report}\n\nè«‹åˆ—å‡ºé€™æ¨£çš„ç”¢å“å¯ä»¥åœ¨ç”šéº¼æ¨£çš„å ´åˆã€å±•è¦½ã€æ´»å‹•æ‰¾åˆ°æ½›åœ¨å®¢æˆ¶')
    print(report)
    # activities_info = mission_search_query(mission='æ‰¾åˆ°æ•¸å€‹å¯èƒ½èƒ½æ‰¾åˆ°å¤§é‡å®¢æˆ¶çš„å±•è¦½èˆ‡æ´»å‹•')
    # print(activities_info)
    conversation_history.append({"role": "assistant", "content": report})

    # user_input = input("ä½ å¯ä»¥åœ¨é€™é‚Šè£œå……æœ‰å“ªäº›å ´åˆå¯ä»¥å–å¾—å®¢æˆ¶è³‡æ–™ï¼š")
    user_input = 'ä½ å·²ç¶“å¹«æˆ‘æ‰¾åˆ°æˆ‘èƒ½æ¨å»£åœ¨å“ªäº›å ´åˆï¼Œç¾åœ¨è«‹å¹«æˆ‘åˆ†ææˆ‘çš„ç”¢å“é‡å°é€™äº›å» å•†æœ‰åˆ†åˆ¥æœ‰å“ªäº›å„ªå‹¢ï¼Œè¶Šè©³ç´°è¶Šå¥½'
    print(user_input)
    conversation_history.append({"role": "user", "content": user_input})
    response = data_Compilation.mission_based_search_and_report(user_input)
    print(response)
    conversation_history.append({"role": "assistant", "content": response})
    #mission = æ‰¾åˆ°é©åˆçš„å±•è¦½èˆ‡æ´»å‹•çµ„åˆæˆlist
    
    #åˆ†æä¸åŒå±•è¦½çš„å„ªå‹¢èˆ‡å¥‘åˆåº¦
    user_input = input("é¸æ“‡ä½ è¦å°‹æ‰¾çš„å±•è¦½ï¼š") 
    user_input = f"ç¾åœ¨æˆ‘æƒ³åˆä½œçš„æ´»å‹•æ˜¯{user_input}ï¼Œè«‹å¹«æˆ‘åˆ†ææœ‰å“ªäº›æ½›åœ¨å» å•†æœƒåœ¨è©²æ´»å‹•ä¸­å‡ºç¾"
    conversation_history.append({"role": "user", "content": user_input})
    response = data_Compilation.mission_based_search_and_report(user_input)
    print(response)
    conversation_history.append({"role": "assistant", "content": response})
    
    #æ’ˆå–æ‰€æœ‰è©²å±•è¦½çš„å» å•†
    user_input = input("é¸å–ä½ è¦çš„å» å•†")
    user_input = f"ç¾åœ¨æˆ‘æƒ³åˆä½œçš„å» å•†æ˜¯{user_input}ï¼Œè«‹å¹«æˆ‘åˆ†ææˆ‘è¦æ€éº¼å°é€™å®¶å» å•†é€²è¡ŒéŠ·å”®"
    conversation_history.append({"role": "user", "content": user_input})
    response = data_Compilation.mission_based_search_and_report(user_input)
    print(response)
    conversation_history.append({"role": "assistant", "content": response})
    
      



